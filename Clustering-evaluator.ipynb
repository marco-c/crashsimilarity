{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from crashsimilarity import utils\n",
    "from crashsimilarity.models.gensim_model_wrapper import Doc2vecModelWrapper\n",
    "from crashsimilarity.evaluator import BugzillaClusters, Metrics as metrics\n",
    "\n",
    "from crashsimilarity.models.similarity.doc2vec_similarity import Doc2VecSimilarity\n",
    "from crashsimilarity.models.wmd_calculator import WMDCalculator\n",
    "from crashsimilarity.models.similarity.base import GenericSimilarity\n",
    "from crashsimilarity.models.distances import edit_distance_structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = pickle.load(open('crashsimilarity_data/objects/vocab.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2vecModelWrapper.load_model('dm_d200')\n",
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = pickle.load(open('crashsimilarity_data/objects/bugzilla_clusters_2015-05-31_2016-05-31.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compress_and_group(prepared):\n",
    "    groups = []\n",
    "    corpus = []\n",
    "    true_labels = []\n",
    "    for p in prepared:\n",
    "        group = []\n",
    "        for t in p:\n",
    "            corpus.append(t)\n",
    "            group.append(len(corpus)-1)\n",
    "            true_labels.append(len(groups))\n",
    "        groups.append(group)\n",
    "    compressed_corpus = [[str(vocab.get(i, i)) for i in c] for c in corpus]\n",
    "    compressed_corpus = [doc2vec.TaggedDocument(trace, [i]) for i, trace in enumerate(compressed_corpus)]\n",
    "    groups = [g for g in groups if len(g) > 1]\n",
    "    return compressed_corpus, corpus, groups, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clear_groups = []\n",
    "for group in clusters.stack_traces:\n",
    "    g = [list(i) for i in group]\n",
    "    g = [i[0] for i in g if i]\n",
    "    tmp = [utils.StackTraceProcessor.preprocess(i) for i in g]\n",
    "    clear_groups.append(tmp)\n",
    "compressed_corpus = []\n",
    "corpus = []\n",
    "group_indexes = []\n",
    "true_labels = []\n",
    "i = 0\n",
    "for group in clear_groups:\n",
    "    for g in group:\n",
    "        cmpr = [str(vocab.get(x, x)) for x in g]\n",
    "        compressed_corpus.append(cmpr)\n",
    "        corpus.append(g)\n",
    "    idx = []\n",
    "    for x in group:\n",
    "        true_labels.append(len(group_indexes))\n",
    "        idx.append(i)\n",
    "        i += 1\n",
    "    group_indexes.append(idx)\n",
    "len(compressed_corpus), len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_matrix(corpus, calculator, prog=10):\n",
    "    dist = np.zeros((len(corpus), len(corpus)), dtype=np.double)\n",
    "    idx = []\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(i + 1, len(corpus)):\n",
    "            idx.append((i, j))\n",
    "    say = len(idx) // prog\n",
    "    t = time.time()\n",
    "    for s, (i, j) in enumerate(idx):\n",
    "        if s and s % say == 0:\n",
    "            print('{}%, {} s.'.format(s / (len(idx) * 0.01), time.time() - t))\n",
    "        dist[i, j] = dist[j, i] = calculator(corpus[i], corpus[j])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wmd_calculator = WMDCalculator.build_with_all_distances(model, compressed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wm_distances = distance_matrix(compressed_corpus, wmd_calculator.wmdistance)\n",
    "wm_distances[wm_distances == np.inf] = -1  #remove inf values\n",
    "m = np.max(wm_distances)\n",
    "wm_distances[wm_distances == -1] = m\n",
    "wm_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "struct_distances = distance_matrix(corpus, edit_distance_structural)\n",
    "struct_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan(dist, eps=0.5, min_samples=2):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed').fit(dist)\n",
    "    n_clusters = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "    return db.labels_, n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(labels_true, labels_pred):\n",
    "    return {'precision': metrics.precision(labels_true, labels_pred), \n",
    "            'recall': metrics.recall(labels_true, labels_pred),\n",
    "            'FMI': metrics.FMI(labels_true, labels_pred),\n",
    "            'n_clusters': len(set(labels_pred)) - (1 if -1 in labels_pred else 0),\n",
    "            'noise': float(len([i for i in labels_pred if i == -1])) / len(labels_true)\n",
    "           }\n",
    "\n",
    "\n",
    "def iterate_eps(dist, labels_true, min_samples=2, eps=None, steps=None):\n",
    "    if eps:\n",
    "        if not isinstance(eps, list):\n",
    "            eps = [eps]\n",
    "    else:\n",
    "        max_dist = np.max(dist)\n",
    "        min_dist = np.min(dist)\n",
    "        steps = steps or 100\n",
    "        eps = np.linspace(min_dist, max_dist, steps)\n",
    "    results = []\n",
    "    for e in eps:\n",
    "        try:\n",
    "            labels_pred, *_ = dbscan(dist, e, min_samples)\n",
    "            results.append((e, report(labels_true, labels_pred)))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wmd_results = iterate_eps(wm_distances, true_labels)\n",
    "sorted(wmd_results, key=lambda x:x[1]['FMI'], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "struct_distances_results = iterate_eps(struct_distances, true_labels)\n",
    "sorted(struct_distances_results, key=lambda x:x[1]['FMI'], reverse=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
